{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish the Model\n",
    "\n",
    "In this notebook, we aim to deploy the registered model from the ML Pipeline task.\n",
    "\n",
    "In the previous step, we manage to create an ML pipeline and run it from the DevOps Build Pipeline. To make that possible, we leveraged Service Principle Identities to log in into our Azure Account from the application to access the ML Workspace. In this notebook, we don't follow this but the Python version of this notebook (located at Score/deploy_model.py) uses the same log-in mechanism, as we need to run the  from the Release Pipeline.\n",
    "\n",
    "To register the model we follow these steps:\n",
    "1. Log in to Azure and get a hold on the Workspace\n",
    "1. Get the latest registered model from the Model Store\n",
    "1. Create a container image from the model\n",
    "1. Deploy the image as a Web Service on Azure Container Instance\n",
    "1. Test the deployed model behind the web service\n",
    "1. Create a Kubernetes cluster\n",
    "1. Deploy the image as a Web Service into the Kubernetes\n",
    "1. Test whether the model is working as expected behind the WebService within the Kubernetes cluster\n",
    "1. Convert this notebook into Python and register it into the Release Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:**:\n",
    "Similar to other notebooks, here are the requirements to run this notebook:\n",
    "\n",
    "In order to practice all parts of the following Notebook, you first need to get a free Azure credit. If you don't have it, you can simply obtain it through this link: https://azure.microsoft.com/en-us/free/\n",
    "\n",
    "You can run this notebook on your local latop, Azure Notebooks (notebooks.azure.com) or Notebook VMs:\n",
    "- Local Laptop - the following packages has to be installed:\n",
    "    - Azureml-SDK - with notebook,widget extensions\n",
    "    - tensorflow==1.13\n",
    "- Azure Notebooks:\n",
    "    - This is a free notebook, all of the packages for an ML experiment is installed\n",
    "- AzureML Notebook:\n",
    "    - This is a premium notebook that you can choose the VM type. Avoid using this feature for the workshop as you may burn your credit before the end or the workshop.\n",
    "\n",
    "Once you chose the execution environment, you need to create an Azure Machine Learning Service. Follow this instruction to build one:\n",
    "\n",
    "The following text is copied from: https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-1st-experiment-sdk-setup#create-a-workspace\n",
    "\n",
    "An Azure Machine Learning workspace is a foundational resource in the cloud that you use to experiment, train, and deploy machine learning models. It ties your Azure subscription and resource group to an easily consumed object in the service.\n",
    "\n",
    "You create a workspace via the Azure portal, a web-based console for managing your Azure resources.\n",
    "\n",
    "1. Sign in to the Azure portal by using the credentials for the Azure subscription you use.\n",
    "1. In the upper-left corner of Azure portal, select + Create a resource.\n",
    "1. Create a new resource\n",
    "1. Use the search bar to find Machine Learning service workspace.\n",
    "1. Select Machine Learning service workspace.\n",
    "1. In the Machine Learning service workspace pane, select Create to begin.\n",
    "1. Provide the following information to configure your new workspace:\n",
    "    - **Field\tDescription**\n",
    "    - **Workspace name**: type in **FirstExample**.\n",
    "    - **Subscription**: Select the Azure subscription that you want to use. (Your free credit)\n",
    "    - **Resource group**: type in **MLOpsWorkshop**\n",
    "    - **Location**: type in **westus2**\n",
    "1. After you are finished configuring the workspace, select Create.\n",
    "When the process is finished, a deployment success message appears.\n",
    "1. To view the new workspace, select Go to resource.\n",
    "\n",
    "\n",
    "You can explore the resource from two view:\n",
    "1. https://portal.azure.com (you can access all resources including Azure ML)\n",
    "1. https://ml.azure.com (recently released - still in preview and dedicated to Azure ML)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.image import ContainerImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your subscription ID will be different replace the stirng with yours\n",
    "subscription_id = \"your_subscription_id\"\n",
    "resource_group = \"your_resource_group\"\n",
    "workspace_name = \"your_workspace_name\"\n",
    "workspace_region = \"your_workspace_region\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Workspace class and check the azureml SDK version\n",
    "# exist_ok checks if workspace exists or not.\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the registered model registered in the last session.\n",
    "\n",
    "You need to make sure the model_name is set property. In order to find out the model_name you registered in the previous session, go to portal.azure.com, click on your Workspace and the from the Asset panel, click on the Models. If you don't see any model registered here, you need to first run the previous lab located at (https://github.com/classicboyir/ml-pipelines/blob/master/MLPipeline_MNIST.ipynb). Clone this repo and follow the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_name = \"tf_mnist_pipeline_devops.model\"\n",
    "model_root = Model(ws, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Provide the dependencies required at the inference time.\n",
    "\n",
    "This code block generates the conda dependency file to load a TF model. You can find the script that is in charge of the inference task. You can check it at here **Score/score.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package('numpy')\n",
    "\n",
    "# Adds all you need for TF\n",
    "cd.add_tensorflow_conda_package() # core_type='cpu', version='1.13')\n",
    "cd.save_to_file(base_directory='./score', conda_file_path='myenv.yml')\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Containerize the model\n",
    "\n",
    "In this task, it builds a docker image containing the model, the dependency file and also the score.py file. The image is registered at the Images section within your Workspace. You can explore it through portal.azure.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "os.chdir('./score')\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"MNIST TF Model\",\n",
    "                                                  tags = {'--release-id': \"0\", 'type': \"TF deployment\"})\n",
    "\n",
    "image = ContainerImage.create(name = \"mnist-image-pipeline\",\n",
    "                              # this is the model object\n",
    "                              models = [model_root],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (With Free Subscription) Deploy the image as a webservice on ACI (Azure Container Instance)\n",
    "\n",
    "In this step, we create an Azure Container Instance to host the image we created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {'area': \"MNIST\", 'type': \"classification\"}, \n",
    "                                               description = 'Predict digits from MNIST dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = 'aci-deployment'\n",
    "\n",
    "try:\n",
    "    aci_service = Webservice(name = aci_service_name, workspace = ws)\n",
    "    print('Found the webservice, deleting the service to add a new one')\n",
    "    aci_service.delete()\n",
    "    print('Old webservice is deleted')\n",
    "except Exception:\n",
    "    print(\"This webservice doesn't exist\")\n",
    "finally:\n",
    "    print('Deploying the new web service')\n",
    "    aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "\n",
    "    aci_service.wait_for_deployment(show_output = True)\n",
    "    print('This webservice is deployed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The URL that the model is accessible is retrievable through the following command. You can pass it to your app developers or test it using any programming language that supports post request. Moreover, you can try Postman to test the deployed web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the deployed model behind the web service\n",
    "Once the image (which includes the model) is registered as a web service, we should now check to see if the model is performing as expected or not. The following code blocks try, downloads the MNIST dataset, select some randomly sampled data, passes the data to the webservice and finally plot the result of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "os.makedirs('./data/mnist', exist_ok=True)\n",
    "\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename = './data/mnist/train-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename = './data/mnist/train-labels.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename = './data/mnist/test-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename = './data/mnist/test-labels.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "\n",
    "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the neural network converge faster.\n",
    "X_train = load_data('./data/mnist/train-images.gz', False) / 255.0\n",
    "y_train = load_data('./data/mnist/train-labels.gz', True).reshape(-1)\n",
    "\n",
    "X_test = load_data('./data/mnist/test-images.gz', False) / 255.0\n",
    "y_test = load_data('./data/mnist/test-labels.gz', True).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# find 30 random samples from test set\n",
    "n = 30\n",
    "sample_indices = np.random.permutation(X_test.shape[0])[0:n]\n",
    "\n",
    "test_samples = json.dumps({\"data\": X_test[sample_indices].tolist()})\n",
    "test_samples = bytes(test_samples, encoding='utf8')\n",
    "\n",
    "# predict using the deployed model\n",
    "result = aci_service.run(input_data=test_samples)\n",
    "\n",
    "# compare actual value vs. the predicted values:\n",
    "i = 0\n",
    "plt.figure(figsize = (20, 1))\n",
    "\n",
    "for s in sample_indices:\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    \n",
    "    # use different color for misclassified sample\n",
    "    font_color = 'red' if y_test[s] != result[i] else 'green'\n",
    "    clr_map = plt.cm.gray if y_test[s] != result[i] else plt.cm.Greys\n",
    "    \n",
    "    plt.text(x=10, y=-10, s=y_test[s], fontsize=18, color=font_color)\n",
    "    plt.imshow(X_test[s].reshape(28, 28), cmap=clr_map)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Free up resources\n",
    "\n",
    "After you're done with the deployment, you should free up resources to avoid unnecessary charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (Non-free subscription) Creating a Kubernetes Cluster\n",
    "\n",
    "In this step, we create one Kubernetes cluster to host the dockerized image and provide it through a web service.\n",
    "\n",
    "**Important Note**:\n",
    "This section requires you to upgrade your subscription from free to pay-as-you-go. Creation of Kubernetes cluster under free subscription is not supported as of now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aks_name = 'aks-deployment'\n",
    "\n",
    "try:\n",
    "    kubeconfig = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found existing AKS service')\n",
    "except Exception:\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    print('Creating a new AKS service...')\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)\n",
    "\n",
    "    aks_target.wait_for_completion(show_output = True)\n",
    "    print(aks_target.provisioning_state)\n",
    "    print(aks_target.provisioning_errors)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(aks_target.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. (Non-free subscription) Registering the dockerized image as a Webservice on the Kubernetes cluster\n",
    "\n",
    "First, we provide the configuration for the web service. We enable app insights to be able to log and monitor the activities of our mode. We can also turn on the auto scaling feature to scale the container as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Set the web service configuration (using default here)\n",
    "aks_config = AksWebservice.deploy_configuration(autoscale_enabled=True,\n",
    "                                                autoscale_min_replicas=1,\n",
    "                                                autoscale_max_replicas=2,\n",
    "                                                collect_model_data=True,\n",
    "                                                enable_app_insights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# In this code block, we register the image under a webservice in Kubernetes cluster:\n",
    "\n",
    "aks_service_name ='mnist-webapp-service-monitored'\n",
    "\n",
    "try:\n",
    "    aks_service = Webservice(name = aks_service_name, workspace = ws)\n",
    "    print('Found the webservice, deleting the service to add a new one')\n",
    "    aks_service.delete()\n",
    "    print('Old webservice is deleted')\n",
    "except Exception:\n",
    "    print(\"This webservice doesn't exist\")\n",
    "finally:\n",
    "    print('Deploying the new web service')\n",
    "    aks_service = Webservice.deploy_from_image(workspace = ws, \n",
    "                                           name = aks_service_name,\n",
    "                                           image = image,\n",
    "                                           deployment_config = aks_config,\n",
    "                                           deployment_target = aks_target)\n",
    "\n",
    "    aks_service.wait_for_deployment(show_output = True)\n",
    "    print('This webservice is deployed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always access the Webservice URL and the authentication keys using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service.get_keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
